{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status', 'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "train_raw = pd.read_csv(\"adult.data\", header = None, names = header_list, na_values=[' ?'])\n",
    "test_raw = pd.read_csv(\"adult.test\", header = None, names = header_list, na_values=[' ?'], skiprows = 1)\n",
    "train_raw.dropna(axis = 0, inplace = True, how = \"any\")\n",
    "test_raw.dropna(axis = 0, inplace = True, how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "y_train = train_raw['income'].apply(lambda x: 1 if x == ' >50K' else 0).values\n",
    "y_test = test_raw['income'].apply(lambda x: 1 if x == ' >50K.' else 0).values\n",
    "\n",
    "num_col = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt']\n",
    "scaler = StandardScaler()\n",
    "train_raw[num_col] = scaler.fit_transform(train_raw[num_col])\n",
    "test_raw[num_col] = scaler.transform(test_raw[num_col])\n",
    "\n",
    "cat_col = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "for i in cat_col:\n",
    "    train_raw[i] = train_raw[i].apply(lambda x: x[1:])\n",
    "    test_raw[i] = test_raw[i].apply(lambda x: x[1:])\n",
    "\n",
    "ohe = OneHotEncoder(categories='auto')\n",
    "feat = ohe.fit_transform(train_raw[cat_col]).toarray()\n",
    "train_cat = pd.DataFrame(feat, columns=ohe.get_feature_names(cat_col))\n",
    "\n",
    "feat = ohe.transform(test_raw[cat_col]).toarray()\n",
    "test_cat = pd.DataFrame(feat, columns=ohe.get_feature_names(cat_col))\n",
    "\n",
    "remove = []\n",
    "for col in train_cat.columns:\n",
    "    if train_cat[col].sum() < 10:\n",
    "        remove.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['relationship_Husband',\n",
    "        'relationship_Not-in-family', 'relationship_Other-relative',\n",
    "        'relationship_Own-child', 'relationship_Unmarried',\n",
    "        'relationship_Wife', 'race_Amer-Indian-Eskimo',\n",
    "        'race_Asian-Pac-Islander', 'race_Black', 'race_Other',\n",
    "        'race_White', 'gender_Female', 'gender_Male',\n",
    "        'occupation_Adm-clerical', 'occupation_Craft-repair',\n",
    "        'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
    "        'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct',\n",
    "        'occupation_Other-service', 'occupation_Priv-house-serv',\n",
    "        'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
    "        'occupation_Sales', 'occupation_Tech-support',\n",
    "        'occupation_Transport-moving', 'education_10th', 'education_11th',\n",
    "        'education_12th', 'education_1st-4th', 'education_5th-6th',\n",
    "        'education_7th-8th', 'education_9th', 'education_Assoc-acdm',\n",
    "        'education_Assoc-voc', 'education_Bachelors',\n",
    "        'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
    "        'education_Preschool', 'education_Prof-school',\n",
    "        'education_Some-college', 'native-country_Cambodia',\n",
    "        'native-country_Canada', 'native-country_China',\n",
    "        'native-country_Columbia', 'native-country_Cuba',\n",
    "        'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
    "        'native-country_El-Salvador', 'native-country_England',\n",
    "        'native-country_France', 'native-country_Germany',\n",
    "        'native-country_Greece', 'native-country_Guatemala',\n",
    "        'native-country_Haiti', 'native-country_Honduras',\n",
    "        'native-country_Hong', 'native-country_Hungary',\n",
    "        'native-country_India', 'native-country_Iran',\n",
    "        'native-country_Ireland', 'native-country_Italy',\n",
    "        'native-country_Jamaica', 'native-country_Japan',\n",
    "        'native-country_Laos', 'native-country_Mexico',\n",
    "        'native-country_Nicaragua',\n",
    "        'native-country_Outlying-US(Guam-USVI-etc)', 'native-country_Peru',\n",
    "        'native-country_Philippines', 'native-country_Poland',\n",
    "        'native-country_Portugal', 'native-country_Puerto-Rico',\n",
    "        'native-country_Scotland', 'native-country_South',\n",
    "        'native-country_Taiwan', 'native-country_Thailand',\n",
    "        'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
    "        'native-country_Vietnam', 'native-country_Yugoslavia',\n",
    "        'workclass_Federal-gov', 'workclass_Local-gov',\n",
    "        'workclass_Private', 'workclass_Self-emp-inc',\n",
    "        'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
    "        'workclass_Without-pay', 'marital-status_Divorced',\n",
    "        'marital-status_Married-AF-spouse',\n",
    "        'marital-status_Married-civ-spouse',\n",
    "        'marital-status_Married-spouse-absent',\n",
    "        'marital-status_Never-married', 'marital-status_Separated',\n",
    "        'marital-status_Widowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.hstack((train_raw[num_col].values, train_cat[order]))\n",
    "test = np.hstack((test_raw[num_col].values, test_cat[order]))\n",
    "adult50k = {'x_train':train, 'x_test':test, 'y_train':y_train, 'y_test':y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "    \n",
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "#train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "#make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "#compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'true': adult50kp['y_test'], 'ypred': ypredprob[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "roc.append({'fp_rate': 0.0, 'tp_rate': 0.0})\n",
    "\n",
    "for i in df.ypred.unique():    \n",
    "    df['ypredpos'] = (df.ypred >= i).astype('float')\n",
    "    tp = np.sum(df['true'] * df['ypredpos'])\n",
    "    tn = np.sum((1 - df['true']) * (1 - df['ypredpos']))\n",
    "    fp = np.sum((1 - df['true']) * df['ypredpos'])\n",
    "    fn = np.sum(df['true'] * (1 - df['ypredpos']))\n",
    "    \n",
    "    tp_rate = tp / (tp + fn)\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    roc.append({'fp_rate': fp_rate, 'tp_rate': tp_rate})\n",
    "    \n",
    "roc.append({'fp_rate': 1.0, 'tp_rate': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df = pd.DataFrame(roc)\n",
    "roc_df.sort_values('fp_rate', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a26b71d90>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "roc_df.plot(x = \"fp_rate\", y = 'tp_rate', kind = 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df['fp_rate_pre'] = roc_df.fp_rate.shift(1)\n",
    "roc_df['tp_rate_pre'] = roc_df.tp_rate.shift(1)\n",
    "roc_df['base'] = roc_df.fp_rate - roc_df.fp_rate_pre\n",
    "roc_df['height'] = (roc_df.tp_rate + roc_df.tp_rate_pre) / 2\n",
    "roc_df['area'] = roc_df.base * roc_df.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.9034904715454891\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC = \", roc_df.area.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of E(w) is: $\\nabla E(w) = \\Lambda w + X^T (y - t)$. \n",
    "\n",
    "The hession of E(w) is $H = X^T R X + \\Lambda$\n",
    "\n",
    "$R$ is a diagonal matrix with $R_{ii} = y_i (1 - y_i)$ and $y_i = \\frac{1}{1 + exp({-w^T x_i})}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        if self.add_intercept: x = np.c_[x, np.ones(x.shape[0])]\n",
    "        \n",
    "        #initial w, with ridge regression\n",
    "        inv_xtx = np.linalg.pinv(np.dot(np.transpose(x), x) + np.diag(self.reg_vec))\n",
    "        w = np.dot(inv_xtx, np.dot(np.transpose(x), y))\n",
    "\n",
    "        obj = np.inf\n",
    "        best_w = None\n",
    "        for i in range(self.max_iter):    \n",
    "            y0 = self.__sigmoid(np.dot(x, w))\n",
    "            #gradient\n",
    "            grad = self.reg_vec * w + np.dot(np.transpose(x), y0 - y)\n",
    "            R = np.diag(y0 * (1-y0))\n",
    "            #hession\n",
    "            hess = np.diag(self.reg_vec) + np.dot(np.transpose(x), np.dot(R, x))\n",
    "            \n",
    "            #newton update\n",
    "            w -= np.dot(np.linalg.inv(hess), grad)\n",
    "            y0 = self.__sigmoid(np.dot(x, w))\n",
    "            now = np.sum(np.square(w) * self.reg_vec) * 0.5  - np.sum(y * np.log(y0) + (1-y) * np.log(1-y0))\n",
    "               \n",
    "            if now < obj:\n",
    "                best_w = w\n",
    "\n",
    "            if (obj - now) < self.tol:\n",
    "                self.cnt = i + 1\n",
    "                break\n",
    "            obj = now\n",
    "            self.w = best_w\n",
    "            self.obj_value = obj\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.add_intercept:\n",
    "            x = np.c_[x, np.ones(x.shape[0])]\n",
    "        ypred = self.__sigmoid(np.dot(x, self.w))\n",
    "        ypred = (ypred >= 0.5).astype('float64')\n",
    "        return(ypred)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def acc(ypred, ytest): return metrics.accuracy_score(ypred, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case 1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8480743691899071\n",
      "continuous-valued w =  [0.00063868 0.02902158 0.00031659 0.18580616 0.02485913]\n",
      "binary-valued w =  [-0.50152492  0.74781984 -1.02439618 -0.29266873 -0.6351957 ]\n",
      "constant term =  -3.3337454041891306\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.ones(x_train.shape[1] + 1)\n",
    "model = mylogistic_l2(reg_vec = lambda_vec, max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "model.fit(x_train, y_train)\n",
    "ypred = model.predict(x_test)\n",
    "\n",
    "print(\"accuracy:\", acc(y_test, ypred))\n",
    "print(\"continuous-valued w = \", model.w[0:5])\n",
    "print(\"binary-valued w = \", model.w[10:15])\n",
    "print(\"constant term = \", model.w[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case 2: lambda = 1 for all but the intercept, no regularization for intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.847808764940239\n",
      "continuous-valued w =  [0.00063965 0.02949145 0.00031702 0.29532492 0.02543368]\n",
      "binary-valued w =  [ 0.07530145  1.28789619 -0.37204838  0.39436062  0.04306939]\n",
      "constant term =  -8.887227775664206\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.ones(x_train.shape[1] + 1)\n",
    "lambda_vec[-1] = 0.0\n",
    "model = mylogistic_l2(reg_vec = lambda_vec, max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "model.fit(x_train, y_train)\n",
    "ypred = model.predict(x_test)\n",
    "\n",
    "print(\"accuracy:\", acc(y_test, ypred))\n",
    "print(\"continuous-valued w = \", model.w[0:5])\n",
    "print(\"binary-valued w = \", model.w[10:15])\n",
    "print(\"constant term = \", model.w[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.84800796812749\n",
      "continuous-valued w =  [0.34995101 0.72781415 0.33261563 0.25677883 2.31859243]\n",
      "binary-valued w =  [-0.07487908  0.00180633 -0.22739145 -0.56278418 -1.06014632]\n",
      "constant term =  -1.0701453793576885\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.ones(x_train.shape[1] + 1) \n",
    "lambda_vec[-1] = 0.0\n",
    "lambda_vec[len(cont_var):] = 15\n",
    "model = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "model.fit(x_train, y_train)\n",
    "ypred = model.predict(x_test)\n",
    "\n",
    "print(\"accuracy:\", acc(ypred, y_test))\n",
    "print(\"continuous-valued w = \", model.w[0:5])\n",
    "print(\"binary-valued w = \", model.w[10:15])\n",
    "print(\"constant term = \", model.w[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "x_subtrain, x_tune, y_subtrain, y_tune = train_test_split(x_train, y_train, test_size = 0.2, random_state = 500)\n",
    "\n",
    "grids = np.logspace(-2, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best a1, a2 are  0.5994842503189409\n"
     ]
    }
   ],
   "source": [
    "step_1 = []\n",
    "for i in grids:\n",
    "    lambda_vec = np.ones(x_train.shape[1] + 1) * i\n",
    "    lambda_vec[-1] = 0.0\n",
    "    model = mylogistic_l2(max_iter = 100, tol = 1e-5, add_intercept = True, reg_vec = lambda_vec)\n",
    "    model.fit(x_subtrain, y_subtrain)\n",
    "    ypred = model.predict(x_tune)\n",
    "    step_1.append(acc(y_tune, ypred))\n",
    "\n",
    "a1_star = grids[step_1.index(max(step_1))]\n",
    "print(\"Best a1, a2 are \", a1_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a2 is 0.01\n"
     ]
    }
   ],
   "source": [
    "#Step 2\n",
    "\n",
    "step_2 = []\n",
    "for i in grids:\n",
    "    lambda_vec = np.ones(x_train.shape[1] + 1) * a1_star\n",
    "    lambda_vec[len(cont_var) : -1] = i\n",
    "    lambda_vec[-1] = 0.0\n",
    "    model = mylogistic_l2(max_iter = 100, tol = 1e-5, add_intercept = True, reg_vec = lambda_vec)\n",
    "    model.fit(x_subtrain, y_subtrain)\n",
    "    ypred = model.predict(x_tune)\n",
    "    step_2.append(acc(y_tune, ypred))\n",
    "    \n",
    "a2_star = grids[step_2.index(max(step_2))]\n",
    "print('new a2 is', a2_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a1 is 0.5994842503189409\n"
     ]
    }
   ],
   "source": [
    "#step 3\n",
    "\n",
    "step_3 = []\n",
    "for i in grids:\n",
    "    lambda_vec = np.ones(x_train.shape[1] + 1) * a2_star\n",
    "    lambda_vec[0:len(cont_var)] = i \n",
    "    lambda_vec[-1] = 0.0\n",
    "    model = mylogistic_l2(max_iter = 100, tol = 1e-5, add_intercept = True, reg_vec = lambda_vec)\n",
    "    model.fit(x_subtrain, y_subtrain)\n",
    "    ypred = model.predict(x_tune)\n",
    "    step_3.append(acc(y_tune, ypred))\n",
    "    \n",
    "a1_star = grids[step_3.index(max(step_3))]\n",
    "print(\"new a1 is\", a1_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final best a1 is 0.5994842503189409 best a2 is 0.01\n",
      "accuracy =  0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "#final step\n",
    "\n",
    "lambda_vec = np.ones(x_train.shape[1] + 1) * a2＿star    \n",
    "lambda_vec[0:len(cont_var)] = a1_star\n",
    "lambda_vec[-1] = 0.0\n",
    "model = mylogistic_l2(reg_vec = lambda_vec, max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "model.fit(x_train, y_train)\n",
    "ypred = model.predict(x_test)\n",
    "\n",
    "print(\"Final best a1 is\", a1_star, \"best a2 is\", a2_star)\n",
    "print(\"accuracy = \", acc(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8456175298804781\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "\n",
    "for i in grids:\n",
    "    log = LogisticRegression(solver = 'lbfgs', C = i, max_iter = 1000)\n",
    "    log.fit(x_subtrain, y_subtrain)\n",
    "    ypred = log.predict(x_tune)\n",
    "    a.append(acc(ypred, y_tune))\n",
    "    \n",
    "log = LogisticRegression(solver = 'lbfgs', C = grids[np.argmax(acc)], max_iter = 1000)\n",
    "log.fit(x_train, y_train)\n",
    "ypred = log.predict(x_test)\n",
    "\n",
    "print(\"Accuracy = \", acc(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.30661570e-01,  6.94465827e-01,  3.34682848e-01,\n",
       "         2.39713877e-01,  1.56066346e+00,  7.37016578e-02,\n",
       "        -7.71439682e-02,  5.89295939e-02, -4.21788191e-02,\n",
       "        -6.77963613e-02,  1.28009902e-01,  2.70708653e-01,\n",
       "        -1.35401885e-01, -1.92220128e-01, -5.61404701e-01,\n",
       "        -2.58625018e-01,  8.76763427e-01, -2.21594451e-01,\n",
       "         6.32474594e-02,  1.06892455e+00, -5.94723017e-02,\n",
       "        -6.31472997e-01, -1.37597703e-01, -8.22142126e-02,\n",
       "         3.23663818e-01, -5.58322619e-02,  4.02955599e-02,\n",
       "         1.74627350e-01, -3.41175353e-01, -1.18250366e-01,\n",
       "        -2.35083992e-02, -2.43074673e-01,  2.42895021e-01,\n",
       "         3.45255190e-02,  3.48503317e-02, -3.32908060e-02,\n",
       "        -5.95511067e-02,  2.99550266e-02, -3.69153386e-02,\n",
       "        -8.33706623e-03, -2.75887870e-02,  3.37426136e-02,\n",
       "         2.53933568e-02,  5.98773360e-02, -2.95466905e-02,\n",
       "        -7.04911609e-03, -4.15550262e-03, -2.81003784e-03,\n",
       "         2.67459891e-03, -2.26127312e-03, -2.34849721e-02,\n",
       "         2.22349374e-04,  1.07175950e-02,  6.75125092e-02,\n",
       "        -2.32044102e-03,  2.33612450e-02, -6.11159264e-03,\n",
       "        -1.32029633e-01, -1.73493998e-02, -1.41005436e-02,\n",
       "        -1.60848891e-02,  7.81265671e-02, -6.24456799e-03,\n",
       "         1.12394529e-03, -2.36448759e-02, -3.11570158e-03,\n",
       "        -6.28628164e-02,  5.00461271e-03, -8.01795800e-03,\n",
       "        -4.57259501e-03,  1.52650413e-01, -3.86026250e-02,\n",
       "         1.07214626e-02, -3.09676408e-02,  1.00849001e-02,\n",
       "         6.08825217e-01, -4.90246416e-01, -3.19448764e-01,\n",
       "        -1.94417524e-01, -4.88018127e-01, -6.13803908e-02,\n",
       "         3.56031332e-01,  2.24029461e-01,  1.70587235e-01,\n",
       "         3.08890139e-01, -8.80657158e-02, -2.04932908e-02,\n",
       "        -7.88887644e-02, -2.99537113e-02,  1.81274919e-02,\n",
       "         1.88543578e-02, -1.94114124e-02, -1.87522792e-02,\n",
       "        -1.59263111e-01, -3.24948874e-02,  4.30874722e-02,\n",
       "         6.04402830e-02, -4.67874864e-02,  8.35965883e-02,\n",
       "        -1.62256797e-02,  1.58193782e-01,  3.97909955e-02]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00064001,  0.02950802,  0.00031724,  0.31203001,  0.02546573,\n",
       "        0.00000075, -0.07407873,  0.22531258, -0.59100468, -0.92609569,\n",
       "        0.10326537,  1.26260115, -0.38124735,  0.40916348,  0.04177907,\n",
       "       -0.26340588,  0.19371067, -0.42871637,  0.42871637,  0.21548869,\n",
       "        0.27959343,  1.01725132, -0.77206083, -0.47322298, -0.04768504,\n",
       "       -0.60200453, -1.88466594,  0.73019517,  0.80576665,  0.507429  ,\n",
       "        0.87344275,  0.12451447,  0.17890016, -0.035214  , -0.00376112,\n",
       "        0.89655079,  0.68866294,  0.23793105,  0.245044  , -0.41663257,\n",
       "       -0.10903934, -0.1035255 , -0.00797818,  0.01868738, -0.05671004,\n",
       "       -1.78473365,  0.20879889,  0.04301917,  1.14778499,  0.53944993,\n",
       "       -0.47404861, -1.40784658,  0.56962509, -1.01433943, -0.01467631,\n",
       "       -0.31906337,  0.51217244,  0.70608502,  0.66263738, -0.62847695,\n",
       "       -0.01548843,  0.16180061, -0.20876262,  0.03402074,  0.09015102,\n",
       "       -0.24872401,  0.22762208,  0.61478852,  0.98943385,  0.22207776,\n",
       "        0.41246778, -0.33821611, -0.29612511, -0.37031001, -0.8743016 ,\n",
       "       -0.43434328,  0.50703988,  0.20926063,  0.21410917, -0.05639588,\n",
       "       -0.02212269, -0.94778609,  0.01342044, -0.31515886, -0.1366725 ,\n",
       "        0.42055196, -0.82653439,  0.71797108,  0.75032251,  0.06021963,\n",
       "        0.25213462,  0.42666562, -0.23697825, -0.06238169, -1.18998244,\n",
       "       -0.56195577,  1.77935304,  1.3897376 , -0.53500879, -1.0496372 ,\n",
       "       -0.64466746, -0.37782142, -9.18618534])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True) \n",
    "model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 相較之下，mylogistic_l2的accuracy更高，然而運行效率相當低"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
